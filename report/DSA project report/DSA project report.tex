% Very simple template for lab reports. Most common packages are already included.
\documentclass[a4paper, 11pt]{article}
\usepackage[utf8]{inputenc} % Change according your file encoding
\usepackage{graphicx}
\usepackage{indentfirst}
\usepackage{url}
\usepackage{float}
\usepackage[T1]{fontenc}

%opening
\title{%
Project Report: Key Value Web Server \\
\large Distributed Systems. Advanced Course.}
\author{Sofia Krylova <krylova@kth.se>, Iosif Koen <iosif@kth.se>}
\date{\today{}}

\begin{document}

\maketitle

\section{Introduction}
In this course, as a mandatory task, we were asked to implement a highly available Key-Value web server, using OmniPaxos library, that was developed in KTH. 

OmniPaxos is an in-development replicated log library implemented in Rust. OmniPaxos aims to hide the complexities of consensus to provide users a replicated log that is as simple to use as a local log. Similar to Raft, OmniPaxos can be used to build strongly consistent services such as replicated state machines. Additionally, the leader election of OmniPaxos offers better resilience to partial connectivity and more flexible and efficient reconfiguration compared to Raft.

The developed web server is fault-tolerant. It is accessed via REST and stores key-value data that can be read in a consistent manner. 

The project's main goal was to give us a hands-on experience with OmniPaxos, consensus, leader election and other components that were covered by the course. 
\section{Main problem}

In this project, we were supposed to build a web server that is made fault-tolerant using omnipaxos.
The web server should be accessed via REST or gRPC and store some data that is
accessed in a consistent manner. Apart from standard GET and POST operations, our web server also supports compare-and-swap (CAS).

\section{Solutions and Evaluation}
\subsection{Architecture}

We have implemented the following architecture:

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{architecture.png}
\caption{Web server architecture}
\end{figure}

Web server application is deployed on a separate machine or container and is mainly responsible for processing incoming requests and synchronising data with OmniPaxos servers.

Each web server has a local storage that keeps the key-value state after each synchronisation. In case of a failure, we can just start a new web server process and run an initial synchronisation, without losing any data.

\subsection{Features}

The developed web server supports the following operations:
\begin{itemize}
	\item Read a value buy its key
	\item Write a new key-value record
	\item Compare and swap value for the given key
\end{itemize}

The detailed workflow for each operation is presented on a corresponding diagram.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{get.png}
\caption{Read a value buy its key}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{post.png}
\caption{Write a new key-value record}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{cas.png}
\caption{Compare and swap value for the given key}
\end{figure}

As you can observe on the given diagrams, we synchronise logs and a local storage with each GET/CAS operation, which ensures a linearisable read.

---- I WOULD DELETE FROM HERE ----

The \verb|utils.rs| module defines several constants which are used in the project, specifically for buffering and timing.
Those constants are:
\begin{verbatim}
use std::time::Duration;

pub const BUFFER_SIZE: usize = 10000;
pub const ELECTION_TIMEOUT: Duration = Duration::from_millis(100);
pub const OUTGOING_MESSAGE_PERIOD: Duration = Duration::from_millis(100);

pub const WAIT_LEADER_TIMEOUT: Duration = Duration::from_millis(500);
pub const WAIT_DECIDED_TIMEOUT: Duration = Duration::from_millis(250);
\end{verbatim}

\begin{itemize}
    \item The \verb|BUFFER_SIZE| is a \verb|usize| constant with a value of 10,000, representing the buffer size for network communications.
    \item The \verb|ELECTION_TIMEOUT| is a Duration constant set to 100 milliseconds. This is the duration before a new election is triggered in the Paxos system if a leader is not detected.
    \item The \verb|OUTGOING_MESSAGE_PERIOD| is a Duration constant, which is set to 100 milliseconds. This duration indicates the interval at which outgoing messages are sent by the Paxos system.
    \item The \verb|WAIT_LEADER_TIMEOUT| is a Duration constant also witch set to 500 milliseconds. This duration is the time the system waits for a leader to be detected before proceeding with other tasks.
    \item Last but not least the \verb|WAIT_DECIDED_TIMEOUT| is a Duration constant set to 250 milliseconds. This duration is the time the system waits for a decision on a key-value pair before checking again.
\end{itemize}
\par
The project uses these constants to ensure consistent timing and buffering settings. They help manage the behavior of the distributed Paxos system, ensuring that elections, message sending, and decision-making are handled with appropriate timing.


\subsection{kv.rs and kv\_controler.rs}
The kv.rs module is responsible for creating a key-value store that allows for easy access and modification of data. To ensure thread safety, it uses a HashMap and a mutex. Moreover, it also incorporates a Snapshot trait that enables the creation and merging of snapshots of the key-value store. We also made sure the storage is a singleton Value to make read and write operations consistent.\par
We used the \verb|fn get_storage()|method that returns an \verb|Arc<Mutex<KVStore>>|

\begin{verbatim}
 pub(crate) fn get_storage() -> Arc<Mutex<KVStore>> {
        unsafe {
            match KV_STORE {
                None => {
                    let kv_store = Arc::new(Mutex::new(KVStore {
                        key_value: HashMap::new(),
                        decided_idx: 0,
                    }));
                    KV_STORE = Some(kv_store.clone());
                    kv_store
                }
                Some(ref kv_store) =>
                    kv_store.clone(),
            }
        }
    }
    
\end{verbatim}

\par
The module kv\_controller.rs is in charge of managing HTTP requests that are linked to the key-value store in a Rust-based web application that utilizes Actix Web, a well-known Rust web framework. Its primary function is to offer two API endpoints that allow for creating and retrieving key-value pairs.

To obtain a value for a specific key from the store, we use the \verb|get(key: Path<String>)|, a GET request can be made to /key-value/{key}. The URL path should include the key parameter, and the response will provide a KeyValueResponse structure or a \verb|"404 Not Found"| status if the key is not found in the store. It is necessary to include the key parameter in the URL path to retrieve the value for that specific key.
\begin{verbatim}
    #[get("/key-value/{key}")]
pub async fn get(key: Path<String>) -> HttpResponse {
    let response = get_kv(key.into_inner()).await;

    return if response.key.is_empty() {
        HttpResponse::NotFound()
            .content_type("application/json")
            .status(StatusCode::NOT_FOUND)
            .finish()
    } else {
        HttpResponse::Ok()
            .content_type("application/json")
            .status(StatusCode::OK)
            .json(response)
    };

\end{verbatim}

\subsection{servers.rs}
The servers.rs component describes an OmniPaxos server that utilizes the Paxos distributed consensus algorithm through the OmniPaxos library. This server is responsible for managing node communication, processing incoming messages, and dispatching outgoing messages.
\par
The OmniPaxos server is executed in a continuous loop by the \verb|run()| method, which operates in an asynchronous manner. This method employs two tokio intervals - \verb|election_interval| for managing election timeouts and \verb|outgoing_interval| for transmitting outgoing messages. Additionally, it monitors the incoming Receiver channel for any new messages and handles them by utilizing the \verb|handle_incoming()| function of the \verb|omni_paxos| instance.
\begin{verbatim}
pub(crate) async fn run(&mut self) {
    let mut outgoing_interval = time::interval(OUTGOING_MESSAGE_PERIOD);
    let mut election_interval = time::interval(ELECTION_TIMEOUT);
    loop {
        tokio::select! {
            biased;
            _ = election_interval.tick() => { self.omni_paxos.lock()
            .unwrap()
            .election_timeout(); },
            _ = outgoing_interval.tick() => { self.send_outgoing_msgs().await; },
            Some(in_msg) = self.incoming.recv() => { self.omni_paxos.lock()
            .unwrap()
            .handle_incoming(in_msg); },
            else => { }
        }
    }
}
\end{verbatim}
\par
The function \verb|configure_persistent_storage()| requires a String type path as input and produces a \verb|PersistentStorageConfig| object as output. It operates by generating a \verb|LogOptions| object and a \verb|sled::Config| object using the path provided, which it then utilizes to create a default \verb|PersistentStorageConfig|.
\begin{verbatim}
      pub(crate) fn configure_persistent_storage(path: String) -> 
      PersistentStorageConfig {
        let log_opts = LogOptions::new(path.clone());
        let mut sled_opts = Config::new();
        sled_opts = Config::path(sled_opts, path.clone());

        // generate default configuration and set user-defined options
        let persist_config = PersistentStorageConfig::with(
            path.to_string(), log_opts, sled_opts);

        persist_config
    }
}
\end{verbatim}
\par
The servers.rs module provides the necessary structure and methods to run an OmniPaxos server, manage communication between nodes in the network, and handle timeouts and message processing.
\subsection{storage.rs}

The management of \verb|key-value storage|, including the creation and retrieval of key-value pairs, as well as synchronization between local storage and the distributed Paxos system, is handled by the \verb|storage.rs| module.
\par
The \verb|sync_decided_kv()| method is responsible for synchronizing the local key-value storage with the distributed Paxos system. This function locks the \verb|KVStore| and selects a server from \verb|OP_SERVER_HANDLERS| randomly. Afterward, it retrieves the decided entries from the server and updates the local \verb|key-value storage|. This method ensures that both snapshotted entries and decided entries are appropriately handled.
\begin{verbatim}
async fn sync_decided_kv() {
    let kv_store = KVStore::get_storage();
    let mut storage = kv_store.lock().unwrap();

    let handler = OP_SERVER_HANDLERS.lock().unwrap();
    let server_id = rand::thread_rng().gen_range(1..PEERS);
    // println!("Chosen server {}", server_id);
    let (server, _, _) = handler.get(&server_id).unwrap();

    let last_idx = server
        .lock()
        .unwrap()
        .get_decided_idx();
    println!("Last index {}", last_idx);
    println!("Local index {}", storage.decided_idx);

    let mut overlap = false;
    if storage.decided_idx == 0 { overlap = true; }
    if last_idx > storage.decided_idx {
        let committed_ents = server
            .lock()
            .unwrap()
            .read_decided_suffix(storage.decided_idx as u64)
            .expect("Failed to read expected entries");

        for (_, ent) in committed_ents.iter().enumerate() {
            match ent {
                LogEntry::Decided(kv_decided) => {
                    storage.decided_idx += 1;
                    storage.key_value.insert(kv_decided.key
                    .clone(), kv_decided.value);
                    println!("Adding value: {:?}, decided idx {} via server {}",
                             kv_decided.value, storage.decided_idx, server_id);
                }
                LogEntry::Snapshotted(kv_snapshotted) => {
                    for (k, v) in &kv_snapshotted.snapshot.snapshotted {
                        storage.decided_idx += 1;
                        storage.key_value.insert(k.clone(), *v);
                        println!("Adding value: {:?}, decided inx {} via server {}",
                                 v, storage.decided_idx, server_id);
                    }
                }
                _ => {} // ignore not committed entries
            }
        }
    }
\end{verbatim}
\par
Overall the storage.rs module provides the functions to create and retrieve key-value pairs while ensuring that the local key-value storage is synchronized with the distributed Paxos system.

\subsection{main.rs}
The \verb|main.rs| module is as its name says our main program and serves as the entry point for the application of \verb|server|. It sets up the OmniPaxos \verb|key-value| store, initializes the servers, and starts the HTTP server. The HTTP server exposes two routes for creating and getting \verb|key-value| pairs.\par
Firstly let's see the \verb|main()| function witch sets up the environment and starts the HTTP server. It first calls the \verb|cleanup()| function to remove any previous storage directories. Next, it initializes the OmniPaxos servers and handlers by calling \verb|initialise_handlers()|. Finally, it starts the Actix HTTP server with two routes for creating and getting key-value pairs.
\begin{verbatim}
async fn main() -> std::io::Result<()> {
    // Clean-up storage
    cleanup();

    OP_SERVER_HANDLERS
        .lock()
        .unwrap()
        .extend(initialise_handlers());

    HttpServer::new(move || App::new().service(create).service(get))
        .bind(("127.0.0.1", 8080))?
        .run()
        .await
}
\end{verbatim}
We can see the methods/functions in our \verb|main| module.
\begin{itemize}
    \item The \verb|cleanup()| function removes any previous storage directories.
    \item The \verb|initialise_channels()| creates sender and receiver channels for the OmniPaxos system.
    \item The \verb|initialise_handlers()| initialize the OmniPaxos servers, handlers, and configurations.
    \item Finally the \verb|recovery()| is use to recover a failed node by recreating its storage and rejoining the network.
\end{itemize}

\subsection{test.rs}
Finally, in the \verb|test.rs| module containing tests for the OmniPaxos key-value store implemented in the main application. It uses the \verb|restest| library to test the HTTP endpoints and \verb|tokio| for asynchronous execution. The tests include creating and getting key-value pairs, both individually and concurrently.
Namely, the test functions are:
\begin{itemize}
    \item \verb|test_create()|
    \item \verb|test_multiple_create()|
    \item \verb|test_get()|
\end{itemize}
\par
To run these tests, one would need to start the server first. Unfortunately, the \verb|restest| library do not provide embedded application testing setups.

---- I WOULD DELETE TO HERE ----


\section{Running the server}
\subsection{Start the server}

In this section, we will explain how to run the server on your local machine.

First of all, choose a free port on your computer, which can be used for the server, and update the configuration. Usually, it is 8000 or 8080, but one may choose whatever port they wish.

The configuration can be changes in the \verb|main| module at the \verb|main()| function: 

\verb|.bind(("127.0.0.1", 8080))?|.

Then you should go to your terminal and run the \verb|cargo run| command or inside from your IDE click the run button on the \verb|main()| function. You should see the following output:

\includegraphics[width=\textwidth,keepaspectratio]{Run.png}

By default, there are 3 running instances of the web server and also 3 instances of OmniPaxos servers.

Now, you can use Postman to perform operations on a web server.

\subsection{Create a key-value record}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{create.png}
\caption{Successful CREATE output}
\end{figure}

\subsection{Read a value by a non-existent key}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{get404.png}
\caption{Unsuccessful READ output}
\end{figure}

\subsection{Read a value by an existent key}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{get200.png}
\caption{Successful READ output}
\end{figure}

\subsection{Compare and swap value for the given key with a wrong old value}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{cas400.png}
\caption{Unsuccessful Compare and Swap output}
\end{figure}

\subsection{Compare and swap value for the given key with a correct old value}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{cas200.png}
\caption{Successful Compare and Swap output}
\end{figure}

Please, keep in mind that this operation return the OLD value. But if we read this key after CAS, we will get a new value

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{getcas.png}
\caption{Updated Value after successful CAS}
\end{figure}

\section{Testing}

Once you started the server, you can also run tests, that are under test module. You should get the similar output:

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth,keepaspectratio]{Test1.png}
\caption{Test output}
\end{figure}

We have developed the following tests:

\begin{itemize}
	\item test\_create(): tests a successful CREATE operation
	\item test\_multiple\_create(): tests multiple successful CREATE operations
	\item test\_get(): tests a successful GET operation
	\item test\_cas(): tests a successful CAS operation
	\item test\_unsuccessful\_cas(): tests an successful CAS operation
\end{itemize}

\section{Conclusions}
In this project, we have implemented a highly-available fault-tolerant web server, that stores and accesses key-value data in a consistent manner. We have implemented operations that are sequential (provided by the OmniPaxos library) and linearisable (ensure by our synchronisation mechanism before each operation).

We also acquired new practical skills, that are based on the knowledge, provided by the course. It gave us an excellent grasp of the course outcome knowledge.
\end{document}
